{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovering groups of correlated metrics\n",
    "\n",
    "For large numbers of metrics, it's not always possible to spot sensible groupings from the correlation matrix alone. \n",
    "\n",
    "This notebook uses hierarchical clustering. The algorithm works like this: \n",
    "\n",
    "1) Starting with the correlation matrix for the individual metrics, find the single highest correlation between any two metrics.\n",
    "\n",
    "2) Create a loading matrix that converts the original dataset into a new one where the two most correlated metrics are grouped, but all others are separate. \n",
    "\n",
    "3) Use this new loading matrix to create a new version of the dataset.\n",
    "\n",
    "4) Calculate the new correlation matrix for the data after the first two metrics are grouped.\n",
    "\n",
    "5) Start a new iteration of 1-4 (looking for the next highest correlation).\n",
    "\n",
    "The algorithm stops when enough metrics have been grouped so that nothing is left that is moderately or highly correlated (a parameter controls the level of grouping).\n",
    "\n",
    "Uses SciPy's `linkage` and `fcluster` to do the actual clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlation_clusters(corr, corr_thresh):\n",
    "\n",
    "    # Clustering uses dissimilarity rather than correlation\n",
    "    dissimilarity = 1.0 - corr\n",
    "    diss_thresh = 1.0 - corr_thresh\n",
    "\n",
    "    # Calculate the order or relative distances between metrics\n",
    "    hierarchy = linkage(squareform(dissimilarity), method='single')\n",
    "\n",
    "    # Determine the groups given the hierarchy and threshold\n",
    "    labels = fcluster(hierarchy, diss_thresh, criterion='distance')\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_clusters(labels, metric_columns):\n",
    "    \n",
    "    # Count number of elements in each cluster\n",
    "    cluster_count = Counter(labels)\n",
    "\n",
    "    # Find the order of the cluster's number of members\n",
    "    cluster_order = {cluster[0]: idx for idx, cluster in enumerate(cluster_count.most_common())}\n",
    "    \n",
    "    # Make a new series of the cluster labels in order\n",
    "    relabeled_clusters = [cluster_order[l] for l in labels]\n",
    "\n",
    "    # Make a new count from the relabeled clusters\n",
    "    relabeled_count = Counter(relabeled_clusters)\n",
    "\n",
    "    # Make a DataFrame listing the group for each of the metrics\n",
    "    labeled_column_df = (\n",
    "        pd.DataFrame(\n",
    "        {'group': relabeled_clusters,\n",
    "         'column': metric_columns}\n",
    "        ).sort_values(['group', 'column'], ascending=[True, True])\n",
    "    )\n",
    "\n",
    "    return labeled_column_df, relabeled_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_load_matrix(labeled_column_df, metric_columns, relabled_count, corr):\n",
    "\n",
    "    # Creates an empty matrix to hold the averaging weights\n",
    "    load_mat = np.zeros((len(metric_columns), len(relabled_count)))\n",
    "    \n",
    "    # Enter the weight for each metric in the loading matrix\n",
    "    for row in labeled_column_df.iterrows():\n",
    "        orig_col = metric_columns.index(row[1][1])\n",
    "        \n",
    "        # Selects columns in the loading matrix that are groups\n",
    "        if relabled_count[row[1][0]]>1:\n",
    "            load_mat[orig_col, row[1][0]] = 1.0 /  (np.sqrt(corr) * float(relabled_count[row[1][0]]))\n",
    "        \n",
    "        # For non-grouped metrix, the weight is 1.0\n",
    "        else:\n",
    "            load_mat[orig_col, row[1][0]] = 1.0\n",
    "\n",
    "    # Make a Boolean series showing which columns are groups\n",
    "    is_group = load_mat.astype(bool).sum(axis=0) > 1\n",
    "    \n",
    "    # Make the column names 'metric_group_n' for the groups, otherwise just the metric name\n",
    "    column_names=['metric_group_{}'.format(d + 1) if is_group[d]\n",
    "                      else labeled_column_df.loc[labeled_column_df['group']==d,'column'].iloc[0]\n",
    "                      for d in range(0, load_mat.shape[1])]\n",
    "    \n",
    "\n",
    "    # Make a DataFrame from the weighted matrix\n",
    "    loadmat_df = pd.DataFrame(load_mat, index=metric_columns, columns=column_names)\n",
    "    \n",
    "    # Create a name column for sorting\n",
    "    loadmat_df['name'] = loadmat_df.index\n",
    "    sort_cols = list(loadmat_df.columns.values)\n",
    "    sort_order = [False] * loadmat_df.shape[1]\n",
    "    sort_order[-1] = True\n",
    "    \n",
    "    # Sort for interpretability\n",
    "    loadmat_df = loadmat_df.sort_values(sort_cols, ascending=sort_order)\n",
    "    \n",
    "    # Drop the name column since this was just used for sorting\n",
    "    loadmat_df = loadmat_df.drop('name', axis=1)\n",
    "    return loadmat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_corr_thresh = 0.5\n",
    "scores_path = \"../metric-scores/socialnet_dataset_scores.csv\"\n",
    "\n",
    "# Load in the metric scores\n",
    "score_data = pd.read_csv(scores_path,index_col=[0,1])\n",
    "score_data.drop('is_churn', axis=1, inplace=True)\n",
    "metric_columns = list(score_data.columns.values)\n",
    "\n",
    "labels = find_correlation_clusters(score_data.corr(), group_corr_thresh)\n",
    "labeled_column_df, relabeled_count = relabel_clusters(labels, metric_columns)\n",
    "loadmat_df = make_load_matrix(labeled_column_df, metric_columns, relabeled_count, group_corr_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_group_1</th>\n",
       "      <th>metric_group_2</th>\n",
       "      <th>account_tenure</th>\n",
       "      <th>dislike_per_month</th>\n",
       "      <th>unfriend_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adview_per_month</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_per_month</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newfriend_per_month</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_per_month</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_per_month</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply_per_month</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_tenure</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dislike_per_month</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfriend_per_month</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     metric_group_1  metric_group_2  account_tenure  \\\n",
       "adview_per_month           0.353553        0.000000             0.0   \n",
       "like_per_month             0.353553        0.000000             0.0   \n",
       "newfriend_per_month        0.353553        0.000000             0.0   \n",
       "post_per_month             0.353553        0.000000             0.0   \n",
       "message_per_month          0.000000        0.707107             0.0   \n",
       "reply_per_month            0.000000        0.707107             0.0   \n",
       "account_tenure             0.000000        0.000000             1.0   \n",
       "dislike_per_month          0.000000        0.000000             0.0   \n",
       "unfriend_per_month         0.000000        0.000000             0.0   \n",
       "\n",
       "                     dislike_per_month  unfriend_per_month  \n",
       "adview_per_month                   0.0                 0.0  \n",
       "like_per_month                     0.0                 0.0  \n",
       "newfriend_per_month                0.0                 0.0  \n",
       "post_per_month                     0.0                 0.0  \n",
       "message_per_month                  0.0                 0.0  \n",
       "reply_per_month                    0.0                 0.0  \n",
       "account_tenure                     0.0                 0.0  \n",
       "dislike_per_month                  1.0                 0.0  \n",
       "unfriend_per_month                 0.0                 1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadmat_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a threshold of 0.5, the algorithm has clustered `adview_per_month`, `like_per_month`, `newfriend_per_month` and `post_per_month` into one group, and `message_per_month` and `reply_per_month` into a second group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the loading matrix:\n",
    "loadmat_df.to_csv('socialnet_dataset_scores_load_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the group lists:\n",
    "group_lists=['|'.join(labeled_column_df[labeled_column_df['group']==g]['column'])\n",
    "                    for g in set(labeled_column_df['group'])]\n",
    "\n",
    "(\n",
    "    pd.DataFrame(group_lists, \n",
    "                 index=loadmat_df.columns.values, \n",
    "                 columns=['metrics'])\n",
    "    .to_csv('socialnet_dataset_scores_groupmets.csv')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
