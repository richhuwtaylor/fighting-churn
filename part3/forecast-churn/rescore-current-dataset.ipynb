{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we score the current customer dataset in preparation for prediction. This involves the following steps:\n",
    "\n",
    "1) Reload the score parameters saved from the historical customer dataset.\n",
    "2) Convert the current customer metrics to scores using the historical dataset\n",
    "statistics.\n",
    "3) Reload the loading matrix created from the historical dataset.\n",
    "4) Calculate average group scores for the current customers using the reloaded\n",
    "loading matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform skewed scores\n",
    "def transform_skew_columns(data, skew_col_names):\n",
    "    for col in skew_col_names:\n",
    "        data[col] = np.log(1.0 + data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a distribution is normal or has thin tails, the most extreme values aren't too extreme relative to the middle of the distribution.\n",
    "\n",
    "If the ditribution of a metric has fat tails, the extreme values are further from the middle of the range, and there are more extreme values. Because of this, we use a 'fat-tails' version of the scoring formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all columns with fat tails and apply a fat-tail score formula\n",
    "def transform_fattail_columns(data, fattail_col_names):\n",
    "    for col in fattail_col_names:\n",
    "        data[col] = np.log(data[col] + np.sqrt(np.power(data[col],2) + 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the previously saved data with the appropriate index columns\n",
    "def reload_churn_data(data_set_path, suffix, is_customer_data):\n",
    "    data_path = data_set_path.replace('.csv', '_{}.csv'.format(suffix))\n",
    "    ic = [0,1] if is_customer_data else 0\n",
    "    churn_data = pd.read_csv(data_path, index_col=ic)\n",
    "    return churn_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Generally, it's a good idea to use scores for all metric groups, and regular (natural scale) metrics for any metric that were not grouped because this is easier for businesspeople to understand. For this reason, `save_segment_data` akes the columns for the groups and then adds the original unscaled metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the columns for the groups and add the original unscaled metrics.\n",
    "def save_segment_data(current_data_grouped, current_data, load_mat_df, data_set_path):\n",
    "    # Determine columns for group metrics\n",
    "    group_cols =  load_mat_df.columns[load_mat_df.astype(bool).sum(axis=0) > 1]\n",
    "    no_group_cols = load_mat_df.columns[load_mat_df.astype(bool).sum(axis=0) == 1]\n",
    "    # Make a version of the dataet for segmenting\n",
    "    segment_df = current_data_grouped[group_cols].join(current_data[no_group_cols])\n",
    "    segment_df.to_csv(data_set_path.replace('.csv', '_current_groupmets_segment.csv'),header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the current customer data\n",
    "def group_current_data(scaled_data, load_mat_df, data_set_path):\n",
    "    # Ensure the dataset columns match the loading matrix order\n",
    "    scaled_data = scaled_data[load_mat_df.index.values]\n",
    "    # Apply the loading matrix to calculate average group scores\n",
    "    grouped_ndarray = np.matmul(scaled_data.to_numpy(), load_mat_df.to_numpy())\n",
    "    \n",
    "    # Convert the result to a DataFrame\n",
    "    current_data_grouped = pd.DataFrame(grouped_ndarray,columns=load_mat_df.columns.values, index=scaled_data.index)\n",
    "    \n",
    "    # Save the result\n",
    "    score_save_path = data_set_path.replace('.csv','_current_groupscore.csv')\n",
    "    current_data_grouped.to_csv(score_save_path,header=True)\n",
    "    print('Saving grouped results to %s' % score_save_path)\n",
    "    return current_data_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_current_data(current_data, score_df, data_set_path):\n",
    "    # Ensure the dataset columns match the score param column\n",
    "    current_data = current_data[score_df.index.values]\n",
    "    \n",
    "    # Subtract the mean and divide by the standard deviation\n",
    "    scaled_data = (current_data-score_df['mean'])/score_df['std']\n",
    "    score_save_path = data_set_path.replace('.csv','_current_scores.csv')\n",
    "    scaled_data.to_csv(score_save_path, header=True)\n",
    "    print('Saving score results to %s' % score_save_path)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescore_metrics(data_set_path):\n",
    "\n",
    "    # Reload the loading matrix\n",
    "    load_mat_df = reload_churn_data(data_set_path, 'load_mat', is_customer_data=False)\n",
    "    \n",
    "    # Reload the parameters saved during scoring\n",
    "    score_df = reload_churn_data(data_set_path, 'score_params', is_customer_data=False)\n",
    "    \n",
    "    # Load the current customer data\n",
    "    current_data = reload_churn_data(data_set_path, 'current', is_customer_data=True)\n",
    "    \n",
    "    assert set(score_df.index.values) == set(current_data.columns.values), \"Data to re-score does not match transform params\"\n",
    "    assert set(load_mat_df.index.values) ==set(current_data.columns.values), \"Data to re-score does not match loading matrix\"\n",
    "\n",
    "    # Transform any columns which were determined to be skewed (i.e. has a skew score)\n",
    "    transform_skew_columns(current_data, score_df[score_df['skew_score']].index.values)\n",
    "    \n",
    "    # Transform any columns which were determined to be fat-tailed (i.e. has a fat-tail score)\n",
    "    transform_fattail_columns(current_data, score_df[score_df['fattail_score']].index.values)\n",
    "    \n",
    "    scaled_data = score_current_data(current_data, score_df, data_set_path)\n",
    "    grouped_data = group_current_data(scaled_data, load_mat_df, data_set_path)\n",
    "    save_segment_data(grouped_data, current_data, load_mat_df, data_set_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving score results to ../../output/socialnet7_dataset2_current_scores.csv\n",
      "Saving grouped results to ../../output/socialnet7_dataset2_current_groupscore.csv\n"
     ]
    }
   ],
   "source": [
    "data_set_path = '../../output/socialnet7_dataset2.csv'\n",
    "rescore_metrics(data_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
