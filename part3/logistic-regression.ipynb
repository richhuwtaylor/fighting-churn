{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import exp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We forecast the probability that a customer in a particular cohort will churn during the lead time before their next renewal. \n",
    "\n",
    "A key feature of the model for forecasting churn and retention is that the relationship between engagement and retention is subject to diminishing returns, i.e.\n",
    "- even the most engaged customer has a chance of churning\n",
    "- even the lear engaged customer has a chance of being retained\n",
    "\n",
    "Although engagement is not directly measurable, we assume that behaviour can be estimated from the customer metrics that we've produced. \n",
    "\n",
    "Each behavioural metric score is multiplied by an engagement strength (weight/coefficient) that captures how much the behaviour (or group of behaviours) contributes to engagement. Overall engagement is the sum of the contributions for each behaviour, plus an _intercept_ term which shifts the sigmoidal curve such that a user with zero engagement (average user) has a realistic probability forecast for retention and churn.\n",
    "\n",
    "We set up the model to predict _retention_ because this is easier to interpret: a positive number ro represent something good is more intuitive than a negative number.\n",
    "\n",
    "<u>Relationship between metrics and retention probability</u>\n",
    "\n",
    "The _retention impact_ of a metric or group of metrics is the difference that it makes to the retention probability for a customer to be one standard deviation above the average in this metric, assuming that all the other metrics are exactly average.\n",
    "\n",
    "If the retention impact for a metric is 2%, a customer who is one standard deviation\n",
    "above average on that metric and average in all the other metrics has a forecast retention probability 2% higher than the average retention probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the data in the form needed for regression\n",
    "def prepare_data(data_set_path, ext='_groupscore', as_retention=True):\n",
    "    score_save_path = data_set_path.replace('.csv', '{}.csv'.format(ext))\n",
    "    grouped_data = pd.read_csv(score_save_path, index_col=[0, 1])\n",
    "    \n",
    "    # Separate the outcome and convert it to Boolean (True for retention)\n",
    "    y = grouped_data['is_churn'].astype(np.bool)\n",
    "    if as_retention: y=~y\n",
    "\n",
    "    # Separate the metrics\n",
    "    X = grouped_data.drop(['is_churn'], axis=1)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def s_curve(x):\n",
    "    return 1.0 - (1.0 / 1.0 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the impact of being one standard deviation above average\n",
    "def calculate_impacts(retain_reg):\n",
    "    # Calculate the churn of a perfectly average customer\n",
    "    average_retain = s_curve(-retain_reg.intercept_)\n",
    "    # For every coefficient, calculate the impact\n",
    "    one_stdev_retain = np.array([s_curve(-retain_reg.intercept_-c) for c in  retain_reg.coef_[0]])\n",
    "    # The impact is the probability difference for one standard deviation above average\n",
    "    one_stdev_impact = one_stdev_retain - average_retain\n",
    "    \n",
    "    return one_stdev_impact, average_retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a summary of the regression model\n",
    "def save_regression_summary(data_set_path, retain_reg,ext=''):\n",
    "    one_stdev_impact, average_retain = calculate_impacts(retain_reg)\n",
    "\n",
    "    # Reuse the metrics in each group in the summary\n",
    "    group_lists = pd.read_csv(data_set_path.replace('.csv', '_groupmets.csv'), index_col=0)\n",
    "    \n",
    "    # Create a DataFrame combining the results\n",
    "    coef_df = pd.DataFrame.from_dict(\n",
    "        {'group_metric_offset':  np.append(group_lists.index, 'offset'),\n",
    "         'weight': np.append(retain_reg.coef_[0], retain_reg.intercept_),\n",
    "         'retain_impact' : np.append(one_stdev_impact, average_retain),\n",
    "         'group_metrics' : np.append(group_lists['metrics'], '(baseline)')})\n",
    "    save_path = data_set_path.replace('.csv', '_logreg_summary{}.csv'.format(ext))\n",
    "    coef_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the regression model itself by pickling it\n",
    "def save_regression_model(data_set_path, retain_reg, ext=''):\n",
    "    pickle_path = data_set_path.replace('.csv', '_logreg_model{}.pkl'.format(ext))\n",
    "    with open(pickle_path, 'wb') as fid:\n",
    "        pickle.dump(retain_reg, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_predictions(data_set_path, retain_reg, X,ext=''):\n",
    "    predictions = retain_reg.predict_proba(X)\n",
    "    \n",
    "    # Make a new DataFrame for saving the predictions\n",
    "    predict_df = pd.DataFrame(predictions, index=X.index, columns=['churn_prob','retain_prob'])\n",
    "    predict_path = data_set_path.replace('.csv', '_predictions{}.csv'.format(ext))\n",
    "    predict_df.to_csv(predict_path,header=True)\n",
    "    print('Saved dataset predictions to ' + predict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LogisticRegression` object takes a few parameters:\n",
    "- `fit_intercept=True` - tells the logistic regression that an offset is included in the model.\n",
    "- `solver='liblinear'`, `penalty='l1'` - control the method used to find weights in the offset. This model uses a ridge regression method, which performs well when many metrics can have correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform logistic regression\n",
    "def logistic_regression(data_set_path, as_retention=True):\n",
    "\n",
    "    # Call the helper function for preparing the data\n",
    "    X,y = prepare_data(data_set_path, as_retention=as_retention)\n",
    "\n",
    "    #Fit the model coefficients based on the churn data\n",
    "    retain_reg = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=True)\n",
    "    retain_reg.fit(X, y)\n",
    "    \n",
    "    # Save a summary of the result, the model, and its predictions\n",
    "    file_ext = '' if as_retention else '_churn'\n",
    "    save_regression_summary(data_set_path, retain_reg, file_ext)\n",
    "    save_regression_model(data_set_path, retain_reg, file_ext)\n",
    "    save_dataset_predictions(data_set_path, retain_reg,X, file_ext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
